# EXP 2: Evaluation of Prompting Tools Across Diverse AI Platforms: ChatGPT, Claude, Bard, Cohere Command, and Meta
ChatGPT, Claude, Bard, Cohere Command, and Meta  
## Aim:
To compare the performance, user experience, and response quality of different AI platforms (ChatGPT, Claude, Bard, Cohere Command, and Meta) within a specific use case, such as summarizing text or answering technical questions. Generate a Prompt based output using different Prompting tools of 2024.
Introduction:
Objective: Compare the performance, user experience, and response quality of AI platforms in a specific use case.
Use Case: Explanatory & Creative Writing
AI Platforms Tested: ChatGPT, Claude, Gemini, Meta

Experiment Setup
Use Case: Concept Explanation & Short-Form Creative Writing
Evaluation Criteria:

Accuracy: Correctness and relevance of the response

Response Time: Speed and responsiveness

UX (User Experience): Clarity, structure, and user-friendly language

### Prompt 1 (Concept Explanation):
"In 3-4 sentences, explain the difference between classical programming and machine learning."

#### ChatGPT:
In classical programming, rules are explicitly coded by developers to process inputs into outputs. Machine learning, by contrast, allows computers to learn patterns from data and make decisions without being explicitly programmed. It is more flexible for tasks like image recognition or language processing. ML systems adapt as they are exposed to more data.

#### Claude:
Classical programming uses fixed rules coded by a programmer, whereas machine learning enables systems to learn from data patterns. This allows ML models to handle more complex, variable tasks. ML adapts over time with more data, while classical code does not.

#### Gemini:
Classical programming follows rules coded manually, while machine learning lets systems learn patterns from data. ML is useful in areas like speech recognition, where explicit coding is too complex. Classical systems remain static unless updated manually.

#### Meta:
Classical programming is based on hardcoded instructions, while machine learning derives logic from data. ML can generalize from examples, making it better suited for tasks where rules are not easily defined. It improves performance as it learns.

### Prompt 2 (Quick Response – General Knowledge):
"Why are electric vehicles considered environmentally friendly? (Answer in 2-3 sentences)"

#### ChatGPT:
Electric vehicles produce zero tailpipe emissions, reducing air pollution and greenhouse gases. They are often more energy-efficient than gasoline vehicles, especially when charged from renewable sources.

#### Claude:
EVs don’t emit pollutants while driving, helping to reduce carbon emissions. If powered by clean energy, their environmental impact is significantly lower than traditional vehicles.

#### Gemini:
EVs emit no exhaust fumes, making them cleaner for the environment. They're more efficient and can use renewable energy sources, unlike gasoline cars.

#### Meta:
Electric vehicles help reduce air pollution because they don’t rely on fossil fuels for power. They’re more sustainable when paired with green energy sources.

### Prompt 3 (Creative Writing):
"Write a short 3-sentence story about a robot trying to understand human humor."

#### ChatGPT:
The robot watched thousands of stand-up clips, analyzing punchlines and crowd reactions. One day, it tried a joke on its creator: “Why did the AI cross the road? To optimize the chicken’s route.” The human burst out laughing—not at the joke, but at the robot’s proud delivery.

#### Claude:
After scanning a million comedy routines, the robot built its first joke generator. “I told my toaster a joke—it didn’t respond. I guess it’s a little too... burnt out,” it said, pausing for laughs. The silence was louder than expected.

#### Gemini:
The robot studied memes and sitcoms to decode laughter. It told a joke about cats programming—then paused. “Was that... humorous?” it asked, unsure why its owner was in tears.

#### Meta:
Every day, the robot tried a new joke it found online. But humans only laughed when it slipped and accidentally played a dog barking sound. “Is error... comedy?” it asked, confused.

## Response Analysis

Platform	Accuracy	Response Time	User Experience	Total Score
ChatGPT  	5/5      	4/5      	5/5	          14/15
Claude   	4/5      	5/5      	5/5          	14/15
Gemini   	4/5      	4/5      	4/5	          12/15
Meta	     4/5	      3/5      	4/5          	11/15

## Final Winner: ChatGPT & Claude (Tie)
Reason: ChatGPT delivered deeply informative and witty responses, while Claude maintained great clarity, especially in creative writing. Gemini was consistent but less expressive, and Meta showed promise but lagged slightly in timing and nuance.

## Conclusion & Insights:
Best Performing AI: ChatGPT & Claude (Tie)
Claude and ChatGPT offer top-tier performance, each with strengths in natural explanations and engaging responses. Gemini was compact and clear but needs more expressiveness. Meta is promising, especially in factual tasks, but slightly behind in creativity and fluency.

## Recommendation:

Use ChatGPT for balanced technical + creative writing.

Choose Claude for speed and elegant phrasing.

Gemini is suitable for short answers and general overviews.

Meta fits quick summaries and factual prompts.


### Algorithm: Design and Develop a Test scenario and execute the prompts under Diverse AI Platforms.

### Program: Write Prompts in different tools , Compare and Analyse the output :

![Screenshot 2025-04-23 085224](https://github.com/user-attachments/assets/0a34ccf9-a6d0-4c0b-9e4c-bf5a00eda3bc)


## Summary :
![Screenshot 2025-04-23 085235](https://github.com/user-attachments/assets/5a80c5ce-4eb5-4226-90a7-ff49c88a5009)


### Result:
Thus the Prompting tools are executed and analysed sucessfully .
